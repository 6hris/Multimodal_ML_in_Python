{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df568ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd007461",
   "metadata": {},
   "source": [
    "# Step 1: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2600b2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of rows in train.csv: 1048575\n",
      "The total number of rows in test.csv: 359\n"
     ]
    }
   ],
   "source": [
    "# load in datasets\n",
    "training_df = pd.read_csv(\"/users/chris/pythonML/train.csv\")\n",
    "testing_df = pd.read_csv(\"/users/chris/pythonML/test.csv\")\n",
    "\n",
    "training_size = len(training_df) # get size of train dataset\n",
    "print(\"The total number of rows in train.csv: \" + str(training_size))\n",
    "\n",
    "testing_size = len(testing_df) # get size of test dataset\n",
    "print(\"The total number of rows in test.csv: \" + str(testing_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f988a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of positive datapoints in train.csv: 248575\n",
      "The total number of negative datapoints in train.csv: 800000\n",
      "The total number of positive datapoints in test.csv: 182\n",
      "The total number of negative datapoints in test.csv: 177\n"
     ]
    }
   ],
   "source": [
    "# count the number of positive and negative data points for train.csv\n",
    "num_positive = len(training_df[training_df['Sentiment'] == 1]) # 1 == positive\n",
    "print(\"The total number of positive datapoints in train.csv: \" + str(num_positive))\n",
    "num_negative = len(training_df[training_df['Sentiment'] == 0]) # 0 == negative\n",
    "print(\"The total number of negative datapoints in train.csv: \" + str(num_negative))\n",
    "# count the number of positive and negative data points for test.csv\n",
    "num_positive = len(testing_df[testing_df['Sentiment'] == 1])\n",
    "print(\"The total number of positive datapoints in test.csv: \" + str(num_positive))\n",
    "num_negative = len(testing_df[testing_df['Sentiment'] == 0])\n",
    "print(\"The total number of negative datapoints in test.csv: \" + str(num_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f47e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if data sets have any empty values\n",
    "print(training_df.isnull().values.any())\n",
    "print(testing_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef99b6e",
   "metadata": {},
   "source": [
    "# Step 2: Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9787c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all words to lower case in our datasets' discussion texts\n",
    "training_df['Text'] = training_df['Text'].str.lower();\n",
    "testing_df['Text'] = testing_df['Text'].str.lower();\n",
    "# remove digital numbers and special characters from our datasets' discussion texts\n",
    "training_df['Text'] = training_df['Text'].str.replace('[^a-zA-Z ]','', regex=True)\n",
    "testing_df['Text'] = testing_df['Text'].str.replace('[^a-zA-Z ]','', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa34d8f",
   "metadata": {},
   "source": [
    "# Step 3: Linguistic Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14d26d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since train.csv is too large to process, we need to get a random subset of the dataframe to perform classification models\n",
    "train_subset = training_df.sample(n=15000, random_state=42) # get subset of 100,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b291fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf*idf feature extraction on training dataset:\n",
      "  (0, 24763)\t0.24895649564318997\n",
      "  (0, 20962)\t0.3706623500033639\n",
      "  (0, 9182)\t0.1910558669130168\n",
      "  (0, 22357)\t0.08168156703437544\n",
      "  (0, 18268)\t0.3296238032191935\n",
      "  (0, 1794)\t0.13509209827149246\n",
      "  (0, 23853)\t0.3706623500033639\n",
      "  (0, 15543)\t0.1419572734348018\n",
      "  (0, 11193)\t0.2578346952641455\n",
      "  (0, 10503)\t0.1190258185859985\n",
      "  (0, 2771)\t0.2659431170843537\n",
      "  (0, 20918)\t0.30074137606212475\n",
      "  (0, 8755)\t0.16640353710342626\n",
      "  (0, 16371)\t0.3238655207467009\n",
      "  (0, 21893)\t0.12891741213817687\n",
      "  (0, 12161)\t0.16632481232173474\n",
      "  (0, 15502)\t0.1312724293531593\n",
      "  (0, 5535)\t0.19261254611504044\n",
      "  (1, 23923)\t0.40753113086212206\n",
      "  (1, 10571)\t0.1250560779971536\n",
      "  (1, 20688)\t0.34575794208200933\n",
      "  (1, 15672)\t0.34575794208200933\n",
      "  (1, 22703)\t0.40753113086212206\n",
      "  (1, 1798)\t0.28449495222825516\n",
      "  (1, 1629)\t0.40753113086212206\n",
      "  :\t:\n",
      "  (14998, 7909)\t0.23106960082716574\n",
      "  (14998, 708)\t0.17002884234928728\n",
      "  (14998, 23864)\t0.21631171769287505\n",
      "  (14998, 9584)\t0.16738800056414502\n",
      "  (14998, 8984)\t0.20534833054496135\n",
      "  (14998, 20773)\t0.23752958567256674\n",
      "  (14998, 10998)\t0.365998930234508\n",
      "  (14998, 19378)\t0.16195413737444128\n",
      "  (14998, 20982)\t0.15843999798243769\n",
      "  (14998, 19392)\t0.23227079455275454\n",
      "  (14998, 10920)\t0.10718196923772093\n",
      "  (14998, 16023)\t0.14115578349743635\n",
      "  (14998, 21914)\t0.1656397887526875\n",
      "  (14998, 3118)\t0.2354650121242817\n",
      "  (14998, 22357)\t0.07747650452689053\n",
      "  (14998, 15543)\t0.13464914713582607\n",
      "  (14999, 12636)\t0.4697510620557226\n",
      "  (14999, 18950)\t0.26549242685157254\n",
      "  (14999, 23928)\t0.3078006211900263\n",
      "  (14999, 22486)\t0.29877122852590926\n",
      "  (14999, 7303)\t0.39050853574756594\n",
      "  (14999, 24357)\t0.21617089023323377\n",
      "  (14999, 19801)\t0.3160039841055359\n",
      "  (14999, 21914)\t0.13361156459401421\n",
      "  (14999, 11152)\t0.4559659012934703\n",
      "Tf*idf feature extraction on testing dataset:\n",
      "  (0, 21914)\t0.23770524839395138\n",
      "  (0, 21893)\t0.17548162179917848\n",
      "  (0, 18576)\t0.2590368679342345\n",
      "  (0, 16102)\t0.34511210750246835\n",
      "  (0, 15502)\t0.17868725735605076\n",
      "  (0, 14853)\t0.13599489869504153\n",
      "  (0, 12047)\t0.4839266157929502\n",
      "  (0, 10947)\t0.18729204206452132\n",
      "  (0, 10872)\t0.29977293128013166\n",
      "  (0, 10571)\t0.1548255209427268\n",
      "  (0, 7084)\t0.4093673890764513\n",
      "  (0, 4415)\t0.3093177649565988\n",
      "  (0, 2977)\t0.1723920864663546\n",
      "  (1, 18026)\t0.33091212852154933\n",
      "  (1, 18022)\t0.305513111722653\n",
      "  (1, 14853)\t0.1308137541323113\n",
      "  (1, 13137)\t0.22402727607029171\n",
      "  (1, 12581)\t0.4405054186391872\n",
      "  (1, 12047)\t0.46548994075414235\n",
      "  (1, 10920)\t0.14795397116470707\n",
      "  (1, 10872)\t0.14417607904520313\n",
      "  (1, 8380)\t0.20228365785445304\n",
      "  (1, 3679)\t0.48532127162138916\n",
      "  (2, 21914)\t0.13544661470307545\n",
      "  (2, 18692)\t0.48172561285954624\n",
      "  :\t:\n",
      "  (356, 6304)\t0.49886155652403547\n",
      "  (356, 1520)\t0.25613443814647746\n",
      "  (356, 359)\t0.44865345289472575\n",
      "  (357, 22808)\t0.27683134508338725\n",
      "  (357, 20311)\t0.11600791474310367\n",
      "  (357, 19378)\t0.15716946322165698\n",
      "  (357, 10846)\t0.8477265220776093\n",
      "  (357, 10571)\t0.10469949087177237\n",
      "  (357, 9357)\t0.255749719983414\n",
      "  (357, 7087)\t0.22367466082380782\n",
      "  (357, 1402)\t0.20040912438820707\n",
      "  (358, 24213)\t0.2728909976082792\n",
      "  (358, 22953)\t0.28871090163173896\n",
      "  (358, 22073)\t0.250134095074972\n",
      "  (358, 21914)\t0.20423441120759162\n",
      "  (358, 21819)\t0.4334995811685795\n",
      "  (358, 18950)\t0.20291166278481956\n",
      "  (358, 18026)\t0.29557795527578645\n",
      "  (358, 16023)\t0.1740455511820824\n",
      "  (358, 15692)\t0.14168423206317352\n",
      "  (358, 10872)\t0.12878122912646933\n",
      "  (358, 10846)\t0.3590233070939931\n",
      "  (358, 10606)\t0.37293577161989067\n",
      "  (358, 4179)\t0.2681775927709597\n",
      "  (358, 763)\t0.12077861780473748\n"
     ]
    }
   ],
   "source": [
    "# extract linguistic features using tf*idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "tf_idf_model = TfidfVectorizer() # create an instance of the TfidfVectorizer class\n",
    "tf_idf_training = tf_idf_model.fit_transform(train_subset['Text']) # fit and transform train.csv text to generate matrix of tf-idf weights\n",
    "print(\"Tf*idf feature extraction on training dataset:\")\n",
    "print(tf_idf_training)\n",
    "\n",
    "# do the same for test.csv\n",
    "tf_idf_testing = tf_idf_model.transform(testing_df['Text'])\n",
    "print(\"Tf*idf feature extraction on testing dataset:\")\n",
    "print(tf_idf_testing)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6700ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words feature extraction on training dataset:\n",
      "  (0, 5535)\t1\n",
      "  (0, 15502)\t1\n",
      "  (0, 12161)\t1\n",
      "  (0, 21893)\t1\n",
      "  (0, 16371)\t1\n",
      "  (0, 8755)\t1\n",
      "  (0, 20918)\t1\n",
      "  (0, 2771)\t1\n",
      "  (0, 10503)\t1\n",
      "  (0, 11193)\t1\n",
      "  (0, 15543)\t1\n",
      "  (0, 23853)\t1\n",
      "  (0, 1794)\t1\n",
      "  (0, 18268)\t1\n",
      "  (0, 22357)\t1\n",
      "  (0, 9182)\t1\n",
      "  (0, 20962)\t1\n",
      "  (0, 24763)\t1\n",
      "  (1, 19648)\t1\n",
      "  (1, 1629)\t1\n",
      "  (1, 1798)\t1\n",
      "  (1, 22703)\t1\n",
      "  (1, 15672)\t1\n",
      "  (1, 20688)\t1\n",
      "  (1, 10571)\t1\n",
      "  :\t:\n",
      "  (14998, 10920)\t1\n",
      "  (14998, 19392)\t1\n",
      "  (14998, 20982)\t1\n",
      "  (14998, 19378)\t1\n",
      "  (14998, 10998)\t2\n",
      "  (14998, 20773)\t1\n",
      "  (14998, 8984)\t1\n",
      "  (14998, 9584)\t1\n",
      "  (14998, 23864)\t1\n",
      "  (14998, 708)\t1\n",
      "  (14998, 7909)\t1\n",
      "  (14998, 827)\t1\n",
      "  (14998, 22241)\t1\n",
      "  (14998, 14431)\t1\n",
      "  (14998, 5347)\t1\n",
      "  (14998, 22661)\t1\n",
      "  (14999, 11152)\t1\n",
      "  (14999, 21914)\t1\n",
      "  (14999, 19801)\t1\n",
      "  (14999, 24357)\t1\n",
      "  (14999, 7303)\t1\n",
      "  (14999, 22486)\t1\n",
      "  (14999, 23928)\t1\n",
      "  (14999, 18950)\t1\n",
      "  (14999, 12636)\t1\n",
      "Bag-of-words feature extraction on testing dataset:\n",
      "  (0, 2977)\t1\n",
      "  (0, 4415)\t1\n",
      "  (0, 7084)\t1\n",
      "  (0, 10571)\t1\n",
      "  (0, 10872)\t2\n",
      "  (0, 10947)\t1\n",
      "  (0, 12047)\t1\n",
      "  (0, 14853)\t1\n",
      "  (0, 15502)\t1\n",
      "  (0, 16102)\t1\n",
      "  (0, 18576)\t1\n",
      "  (0, 21893)\t1\n",
      "  (0, 21914)\t2\n",
      "  (1, 3679)\t1\n",
      "  (1, 8380)\t1\n",
      "  (1, 10872)\t1\n",
      "  (1, 10920)\t1\n",
      "  (1, 12047)\t1\n",
      "  (1, 12581)\t1\n",
      "  (1, 13137)\t1\n",
      "  (1, 14853)\t1\n",
      "  (1, 18022)\t1\n",
      "  (1, 18026)\t1\n",
      "  (2, 7369)\t1\n",
      "  (2, 7868)\t1\n",
      "  :\t:\n",
      "  (356, 13186)\t1\n",
      "  (356, 18032)\t1\n",
      "  (356, 21847)\t1\n",
      "  (357, 1402)\t1\n",
      "  (357, 7087)\t1\n",
      "  (357, 9357)\t1\n",
      "  (357, 10571)\t1\n",
      "  (357, 10846)\t3\n",
      "  (357, 19378)\t1\n",
      "  (357, 20311)\t1\n",
      "  (357, 22808)\t1\n",
      "  (358, 763)\t1\n",
      "  (358, 4179)\t1\n",
      "  (358, 10606)\t1\n",
      "  (358, 10846)\t1\n",
      "  (358, 10872)\t1\n",
      "  (358, 15692)\t1\n",
      "  (358, 16023)\t1\n",
      "  (358, 18026)\t1\n",
      "  (358, 18950)\t1\n",
      "  (358, 21819)\t1\n",
      "  (358, 21914)\t2\n",
      "  (358, 22073)\t1\n",
      "  (358, 22953)\t1\n",
      "  (358, 24213)\t1\n"
     ]
    }
   ],
   "source": [
    "# extract linguistic features using bag-of-words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer() # create an instance of CountVectorizer\n",
    "bow_matrix_train = bow.fit_transform(train_subset['Text']) # fit the vectorizer to train.csv text and transform into a bow matrix\n",
    "print(\"Bag-of-words feature extraction on training dataset:\")\n",
    "print(bow_matrix_train)\n",
    "\n",
    "# do the same for test.csv\n",
    "bow_matrix_test = bow.transform(testing_df['Text']) \n",
    "print(\"Bag-of-words feature extraction on testing dataset:\")\n",
    "print(bow_matrix_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cf0a0",
   "metadata": {},
   "source": [
    "# Step 4: Build your sentiment classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a778905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for machine learning classification models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b1aff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.94      0.77       177\n",
      "           1       0.90      0.51      0.65       182\n",
      "\n",
      "    accuracy                           0.72       359\n",
      "   macro avg       0.78      0.72      0.71       359\n",
      "weighted avg       0.78      0.72      0.71       359\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chris/opt/anaconda3/envs/assignment1.0/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# set y_train and y_test to sentiment portion of database\n",
    "y_train = train_subset['Sentiment']\n",
    "y_test = testing_df['Sentiment']\n",
    "\n",
    "# create logistic regression model on bag-of-words feature extraction \n",
    "lc_bag = LogisticRegression(random_state=42)\n",
    "lc_bag.fit(bow_matrix_train, y_train)\n",
    "\n",
    "y_lc_bag_predicted = lc_bag.predict(bow_matrix_test) # predict test data\n",
    "\n",
    "print(classification_report(y_test, y_lc_bag_predicted)) # print results of logistic regression model w/ bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f33d361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.97      0.73       177\n",
      "           1       0.92      0.32      0.48       182\n",
      "\n",
      "    accuracy                           0.64       359\n",
      "   macro avg       0.75      0.65      0.60       359\n",
      "weighted avg       0.75      0.64      0.60       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create logistic regression model on tf*idf feature extraction\n",
    "lc_tf_idf = LogisticRegression(random_state=42)\n",
    "lc_tf_idf.fit(tf_idf_training, y_train)\n",
    "\n",
    "y_lc_tf_idf_predicted = lc_tf_idf.predict(tf_idf_testing) # predict test data\n",
    "\n",
    "print(classification_report(y_test, y_lc_tf_idf_predicted)) # print results of logistic regression model w/ tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da33a200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.87      0.75       177\n",
      "           1       0.81      0.55      0.66       182\n",
      "\n",
      "    accuracy                           0.71       359\n",
      "   macro avg       0.73      0.71      0.70       359\n",
      "weighted avg       0.74      0.71      0.70       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create SVM model on bag-of-words feature extraction\n",
    "svm_bag = SVC(kernel='linear')\n",
    "svm_bag.fit(bow_matrix_train, y_train)\n",
    "\n",
    "y_svm_bag_predicted = svm_bag.predict(bow_matrix_test) # predict test data\n",
    "print(classification_report(y_test, y_svm_bag_predicted)) # print results of SVM model w/ bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e20484a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.78       177\n",
      "           1       0.92      0.51      0.65       182\n",
      "\n",
      "    accuracy                           0.73       359\n",
      "   macro avg       0.79      0.73      0.71       359\n",
      "weighted avg       0.79      0.73      0.71       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create SVM model on tf*idf feature extraction\n",
    "svm_tf_idf = SVC(kernel='linear')\n",
    "svm_tf_idf.fit(tf_idf_training, y_train)\n",
    "\n",
    "y_svm_tf_idf_predicted = svm_tf_idf.predict(tf_idf_testing) # predict test data\n",
    "print(classification_report(y_test, y_svm_tf_idf_predicted)) # print results of SVM model w/ tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79776f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       177\n",
      "           1       0.93      0.22      0.36       182\n",
      "\n",
      "    accuracy                           0.60       359\n",
      "   macro avg       0.74      0.60      0.53       359\n",
      "weighted avg       0.74      0.60      0.53       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create Naive Bayes model on bag-of-words feature extraction\n",
    "nb_bag = MultinomialNB()\n",
    "nb_bag.fit(bow_matrix_train, y_train)\n",
    "\n",
    "y_nb_bag_predicted = nb_bag.predict(bow_matrix_test) # predict test data\n",
    "print(classification_report(y_test, y_nb_bag_predicted)) # print results of Naive Bayes model w/ bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2a50b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      1.00      0.66       177\n",
      "           1       1.00      0.00      0.00       182\n",
      "\n",
      "    accuracy                           0.49       359\n",
      "   macro avg       0.75      0.50      0.33       359\n",
      "weighted avg       0.75      0.49      0.33       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create Naive Bayes model on tf*idf feature extraction\n",
    "nb_tf_idf = MultinomialNB()\n",
    "nb_tf_idf.fit(tf_idf_training, y_train)\n",
    "\n",
    "y_nb_tf_idf_predicted = nb_tf_idf.predict(tf_idf_testing) # predict test data\n",
    "print(classification_report(y_test, y_nb_tf_idf_predicted,zero_division=1)) # print results of Naive Bayes model w/ tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a79dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71       177\n",
      "           1       0.91      0.23      0.37       182\n",
      "\n",
      "    accuracy                           0.60       359\n",
      "   macro avg       0.73      0.60      0.54       359\n",
      "weighted avg       0.74      0.60      0.53       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create Random Forest model on bag-of-words feature extraction\n",
    "rf_bag = RandomForestClassifier()\n",
    "rf_bag.fit(bow_matrix_train, y_train)\n",
    "\n",
    "y_rf_bag_predicted = rf_bag.predict(bow_matrix_test) # predict test data\n",
    "print(classification_report(y_test, y_rf_bag_predicted)) # print results of Random Forest model w/ bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66d31e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.70       177\n",
      "           1       0.93      0.21      0.34       182\n",
      "\n",
      "    accuracy                           0.59       359\n",
      "   macro avg       0.74      0.60      0.52       359\n",
      "weighted avg       0.74      0.59      0.52       359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create Random Forest model on tf*idf feature extraction\n",
    "rf_tf_idf = RandomForestClassifier()\n",
    "rf_tf_idf.fit(tf_idf_training, y_train)\n",
    "\n",
    "y_rf_tf_idf_predicted = rf_tf_idf.predict(tf_idf_testing) # predict test data\n",
    "print(classification_report(y_test, y_rf_tf_idf_predicted)) # print results of Random Forest model w/ tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f999010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
